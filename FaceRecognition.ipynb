{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Face Recognition**"
      ],
      "metadata": {
        "id": "ytaDRCwkeMha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before testing**"
      ],
      "metadata": {
        "id": "8Qa2v1xNejgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1ANxypcqFfG"
      },
      "outputs": [],
      "source": [
        "# Mounting to google drive to retreive dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Installing the face_recognition library\n",
        "!pip install face_recognition\n",
        "\n",
        "# Importing random for random training image visualization and matplotlib.pyplot for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Importing argparse for CLI(terminal) use\n",
        "import argparse\n",
        "\n",
        "# Importing pickle for saving encodings\n",
        "import pickle\n",
        "\n",
        "# Importing Counter for votes tracking\n",
        "from collections import Counter\n",
        "\n",
        "# Importing Path for path related commands\n",
        "from pathlib import Path\n",
        "\n",
        "# Importing face_recognition for face recognition\n",
        "import face_recognition\n",
        "\n",
        "# Importing Image and ImageDraw for drawing on an existing image\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Paths to images and titles\n",
        "image_paths = [\"/content/drive/MyDrive/FRD/unknown.jpg\", \"/content/drive/MyDrive/FRD/output/recognized_faces.jpg\"]\n",
        "titles = [\"Unknown Image\", \"Recognized Faces\"]\n",
        "\n",
        "# Default path here to save encodings\n",
        "DEFAULT_ENCODINGS_PATH = Path(\"/content/drive/MyDrive/FRD/output/encodings.pkl\")\n",
        "\n",
        "# Defining bounding box and text color for face recognition\n",
        "BOUNDING_BOX_COLOR = \"blue\"\n",
        "TEXT_COLOR = \"white\"\n",
        "\n",
        "# Parse command-line arguments for adding arguments in terminal\n",
        "parser = argparse.ArgumentParser(description=\"Recognize faces in an image\")\n",
        "parser.add_argument(\"--train\", action=\"store_true\", help=\"Train on input data\")\n",
        "parser.add_argument(\n",
        "    \"--validate\", action=\"store_true\", help=\"Validate trained model\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--test\", action=\"store_true\", help=\"Test the model with an unknown image\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"-m\",\n",
        "    action=\"store\",\n",
        "    default=\"hog\",\n",
        "    choices=[\"hog\", \"cnn\"],\n",
        "    help=\"Which model to use for training: hog (CPU), cnn (GPU)\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"-f\", action=\"store\", help=\"Path to an image with an unknown face\"\n",
        ")\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Function to display bounding boxes and names on detected faces with 2 cases colors coloring\n",
        "def _display_face(draw, bounding_box, name, is_known):\n",
        "    \"\"\"\n",
        "    Draws bounding boxes around faces, a caption area, and text captions.\n",
        "    \"\"\"\n",
        "    top, right, bottom, left = bounding_box\n",
        "    if is_known:\n",
        "        box_color = BOUNDING_BOX_COLOR\n",
        "    else:\n",
        "        box_color = \"red\"\n",
        "    draw.rectangle(((left, top), (right, bottom)), outline=box_color)\n",
        "    text_left, text_top, text_right, text_bottom = draw.textbbox(\n",
        "        (left, bottom), name\n",
        "    )\n",
        "    draw.rectangle(\n",
        "        ((text_left, text_top), (text_right, text_bottom)),\n",
        "        fill=box_color,\n",
        "        outline=box_color,\n",
        "    )\n",
        "    draw.text(\n",
        "        (text_left, text_top),\n",
        "        name,\n",
        "        fill=TEXT_COLOR,\n",
        "    )\n",
        "\n",
        "# Function to recognize a face from its encoding\n",
        "def _recognize_face(unknown_encoding, loaded_encodings):\n",
        "    \"\"\"\n",
        "    Given an unknown encoding and all known encodings, it finds the known\n",
        "    encoding with the most matches.\n",
        "    \"\"\"\n",
        "    boolean_matches = face_recognition.compare_faces(\n",
        "        loaded_encodings[\"encodings\"], unknown_encoding\n",
        "    )\n",
        "    votes = Counter(\n",
        "        name\n",
        "        for match, name in zip(boolean_matches, loaded_encodings[\"names\"])\n",
        "        if match\n",
        "    )\n",
        "    if votes:\n",
        "        return votes.most_common(1)[0][0]\n",
        "\n",
        "# Function to encode known faces\n",
        "def encode_known_faces(\n",
        "    model: str = \"hog\", encodings_location: Path = DEFAULT_ENCODINGS_PATH\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Loads images in the training directory, builds a dictionary of their\n",
        "    names and encodings and displays one random image for each person present in a database.\n",
        "    \"\"\"\n",
        "    # Displays a random image for each person in the training directory\n",
        "    fig, axes = plt.subplots(1, 8, figsize=(16, 4))\n",
        "    for ax, person_dir in zip(axes, Path(\"/content/drive/MyDrive/FRD/training\").glob(\"*\")):\n",
        "        if person_dir.is_dir():\n",
        "            name = person_dir.name\n",
        "            image_files = list(person_dir.glob(\"*\"))\n",
        "            if image_files:\n",
        "                random_image = random.choice(image_files)\n",
        "                image = face_recognition.load_image_file(random_image)\n",
        "                ax.imshow(image)\n",
        "                ax.axis(\"off\")\n",
        "                ax.set_title(name)\n",
        "    plt.tight_layout(pad=1.0)\n",
        "    plt.show()\n",
        "    # Encoding faces in the training images\n",
        "    names = []\n",
        "    encodings = []\n",
        "    for person_dir in Path(\"/content/drive/MyDrive/FRD/training\").glob(\"*\"):\n",
        "        if person_dir.is_dir():\n",
        "            name = person_dir.name\n",
        "            image_files = list(person_dir.glob(\"*\"))\n",
        "            if image_files:\n",
        "                random_image = random.choice(image_files)\n",
        "                image = face_recognition.load_image_file(random_image)\n",
        "                face_locations = face_recognition.face_locations(image, model=model)\n",
        "                face_encodings = face_recognition.face_encodings(image, face_locations, num_jitters=50)\n",
        "                for encoding in face_encodings:\n",
        "                    names.append(name)\n",
        "                    encodings.append(encoding)\n",
        "    name_encodings = {\"names\": names, \"encodings\": encodings}\n",
        "    with encodings_location.open(mode=\"wb\") as f:\n",
        "        pickle.dump(name_encodings, f)\n",
        "\n",
        "# Function to recognize faces in an image\n",
        "def recognize_faces(\n",
        "    image_location: str,\n",
        "    model: str = \"hog\",\n",
        "    encodings_location: Path = DEFAULT_ENCODINGS_PATH,\n",
        "    output_location: str = \"/content/drive/MyDrive/FRD/output/recognized_faces.jpg\"\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Given an unknown image, it gets the locations and encodings of faces,\n",
        "    compares them against the known encodings to find potential matches and\n",
        "    returns the accuracy of the recognition.\n",
        "    \"\"\"\n",
        "    with encodings_location.open(mode=\"rb\") as f:\n",
        "        loaded_encodings = pickle.load(f)\n",
        "    input_image = face_recognition.load_image_file(image_location)\n",
        "    input_face_locations = face_recognition.face_locations(\n",
        "        input_image, model=model\n",
        "    )\n",
        "    input_face_encodings = face_recognition.face_encodings(\n",
        "        input_image, input_face_locations, num_jitters=50\n",
        "    )\n",
        "    pillow_image = Image.fromarray(input_image)\n",
        "    draw = ImageDraw.Draw(pillow_image)\n",
        "    true_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    for bounding_box, unknown_encoding in zip(\n",
        "        input_face_locations, input_face_encodings\n",
        "    ):\n",
        "        name = _recognize_face(unknown_encoding, loaded_encodings)\n",
        "        if name:\n",
        "            is_known = True\n",
        "        else:\n",
        "            is_known = False\n",
        "            name = \"Unknown\"\n",
        "        _display_face(draw, bounding_box, name, is_known)\n",
        "        if is_known and name == \"Unknown\":\n",
        "            false_positives += 1\n",
        "        elif not is_known and name == \"Unknown\":\n",
        "            true_negatives += 1\n",
        "        elif is_known and name != \"Unknown\":\n",
        "            true_positives += 1\n",
        "        elif not is_known and name != \"Unknown\":\n",
        "            false_negatives += 1\n",
        "    accuracy = (true_positives + true_negatives) / (true_positives + false_negatives + false_positives + true_negatives)\n",
        "    del draw\n",
        "    pillow_image.save(output_location)\n",
        "    print(\"Image with recognized faces saved at:\", output_location)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    return accuracy\n",
        "\n",
        "# Validation\n",
        "def validate(model: str = \"hog\"):\n",
        "    \"\"\"\n",
        "    It runs recognize_faces on a set of images with known faces to validate\n",
        "    known encodings.\n",
        "    \"\"\"\n",
        "    accuracies = []\n",
        "    for filepath in Path(\"/content/drive/MyDrive/FRD/validation\").rglob(\"*\"):\n",
        "        if filepath.is_file():\n",
        "            accuracy = recognize_faces(image_location=str(filepath.absolute()), model=model)\n",
        "            accuracies.append(accuracy)\n",
        "    mean_accuracy = sum(accuracies) / len(accuracies)\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "\n",
        "# Function to display images horizontally\n",
        "def display_images_horizontally(image_paths, titles, output_path):\n",
        "    fig, axes = plt.subplots(1, len(image_paths), figsize=(4, 4))\n",
        "    for ax, image_path, title in zip(axes, image_paths, titles):\n",
        "        image = Image.open(image_path)\n",
        "        ax.imshow(image)\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(title)\n",
        "    plt.subplots_adjust(wspace=0)\n",
        "    plt.savefig(output_path)\n",
        "    plt.show()\n",
        "\n",
        "'''def display_images_with_cropped_faces(image_paths, titles, output_path):\n",
        "    fig, axes = plt.subplots(2, len(image_paths), figsize=(16, 8))\n",
        "    for ax, image_path, title in zip(axes[0], image_paths, titles):\n",
        "        image = Image.open(image_path)\n",
        "        ax.imshow(image)\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(title)\n",
        "    for i, person_dir in enumerate(Path(\"/content/drive/MyDrive/FRD/training\").glob(\"*\")):\n",
        "        if person_dir.is_dir():\n",
        "            image_files = list(person_dir.glob(\"*\"))\n",
        "            if image_files:\n",
        "                random_image = random.choice(image_files)\n",
        "                image = face_recognition.load_image_file(random_image)\n",
        "                face_locations = face_recognition.face_locations(image, model=args.m)\n",
        "                if face_locations:\n",
        "                    top, right, bottom, left = face_locations[0]\n",
        "                    cropped_face = image[top:bottom, left:right]\n",
        "                    axes[1, i].imshow(cropped_face)\n",
        "                    axes[1, i].axis(\"off\")\n",
        "                    axes[1, i].set_title(person_dir.name)\n",
        "    plt.tight_layout(pad=1.0)\n",
        "    plt.savefig(output_path)\n",
        "    plt.show()'''\n",
        "\n",
        "# Calling the function to encode known faces\n",
        "encode_known_faces(model=args.m)\n",
        "\n",
        "# display_images_with_cropped_faces(image_paths, titles, \"/content/drive/MyDrive/FRD/output/display_result_with_cropped_faces.jpg\")\n",
        "\n",
        "# Validation\n",
        "validate(model=args.m)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "iFRRFSQVeb70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recognizing faces in unknown image\n",
        "recognize_faces(image_location=\"/content/drive/MyDrive/FRD/unknown.jpg\", model=args.m)\n",
        "\n",
        "# Displaying images horizontally\n",
        "display_images_horizontally(image_paths, titles, \"/content/drive/MyDrive/FRD/output/display_result.jpg\")"
      ],
      "metadata": {
        "id": "YVDYIFxlqJXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Seeing how similar 2 faces are instead of just checking if they match or not can be done by using the **face_distance** fonction.\n",
        "* The model implemented here was trained in a way that faces with a distance of **0.6** or less matches.\n",
        "* For a more strict approch, looking for a **smaller** face distance could be done.\n",
        "* **For exemple**, using a **0.55 cutoff reduces false positive matches at the cost of higher false negatives**.\n",
        "* In a case where higher security mesures are demanded, lowering the **face_distance** fonction could be done."
      ],
      "metadata": {
        "id": "1jbHcR1gqRUz"
      }
    }
  ]
}