Abed El Rahmane Jaafir: [Matricule]: "210 950"; [Email]: "abedelrahmane.jaafir@net.usj.edu.lb"
Nicolas Lawandos: [Matricule]: "201161"; [Email]: "nicolas.lawandos@net.usj.edu.lb"


3D scenes generator from 2D images 

The goal of this project is to reconstruct accurate 3D maps (scenes) from many different views. This project could unlock mapping from assorted and noisy data sources, such as images uploaded by users to some services. Someone's camera may just be the phone in his pocket. He might take a snap of a landmark, then share it with friends. By itself, that photo is two-dimensional and only includes the perspective of his shooting location. Of course, many people may have taken photos of that same landmark. If someone were able to combine all of these photos, he may be able to make a more complete, three-dimensional view of a given thing. Machine learning could help by using vast amounts of unstructured image collections available on the internet. The process of reconstructing a 3D model of an environment from a collection of images is called Structure from Motion (SfM). These images are often captured by trained operators or with additional sensor data, such as some cars. This ensures homogeneous, high-quality data. It is much more difficult to build 3D models from assorted images, given a wide variety of viewpoints, along with lighting, weather, and other changes.
