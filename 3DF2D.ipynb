{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3d372c",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:12.979193Z",
          "iopub.status.busy": "2023-06-22T11:51:12.978391Z",
          "iopub.status.idle": "2023-06-22T11:51:28.510680Z",
          "shell.execute_reply": "2023-06-22T11:51:28.509066Z"
        },
        "papermill": {
          "duration": 15.552396,
          "end_time": "2023-06-22T11:51:28.515834",
          "exception": false,
          "start_time": "2023-06-22T11:51:12.963438",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3d372c",
        "outputId": "534a2b84-b64b-41df-ba2e-b38da31807e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.7.2-py2.py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia-rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.0)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.1->kornia)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, kornia-rs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kornia\n",
            "Successfully installed kornia-0.7.2 kornia-rs-0.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.16\n",
            "Collecting pycolmap\n",
            "  Downloading pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycolmap) (1.25.2)\n",
            "Installing collected packages: pycolmap\n",
            "Successfully installed pycolmap-0.6.1\n",
            "Kornia version 0.7.2\n",
            "Pycolmap version 0.6.1\n"
          ]
        }
      ],
      "source": [
        "# General utilities\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from fastprogress import progress_bar\n",
        "import gc\n",
        "import math\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import concurrent.futures\n",
        "# CV/ML\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from PIL import Image\n",
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "# It was said:\n",
        "from timm.data.transforms_factory import create_transform\n",
        "# was said.\n",
        "# 3D reconstruction\n",
        "import pycolmap\n",
        "print(\"Kornia version\", K.__version__)\n",
        "print(\"Pycolmap version\", pycolmap.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb12982",
      "metadata": {
        "papermill": {
          "duration": 0.01991,
          "end_time": "2023-06-22T11:51:28.568906",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.548996",
          "status": "completed"
        },
        "tags": [],
        "id": "4fb12982"
      },
      "source": [
        "# Global Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee4b45a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:28.601217Z",
          "iopub.status.busy": "2023-06-22T11:51:28.600832Z",
          "iopub.status.idle": "2023-06-22T11:51:28.680459Z",
          "shell.execute_reply": "2023-06-22T11:51:28.679213Z"
        },
        "papermill": {
          "duration": 0.09991,
          "end_time": "2023-06-22T11:51:28.682735",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.582825",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ee4b45a",
        "outputId": "1de8f510-d8f3-4913-d69e-26ce00cb0d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# This is used to find the image directory.\n",
        "MODE = \"train\"\n",
        "MODE = \"test\"\n",
        "# Option to change path for local testing\n",
        "is_local = True\n",
        "is_local = False\n",
        "if is_local:\n",
        "    NUM_CORES = 2\n",
        "    SRC = \"/3DF2DD/3DF2D\"\n",
        "    MODEL_DIR = \"/3DF2DD/KW\"\n",
        "    DISK_PATH = \"/3DF2DD/LD.ckpt\"\n",
        "    HARDNET_PT = \"/3DF2DD/hardnet8v2/hardnet8v2.pt\"\n",
        "else:\n",
        "    NUM_CORES = 2\n",
        "    SRC = \"/3DF2DD/3DF2D\"\n",
        "    MODEL_DIR = \"/3DF2DD/KW\"\n",
        "    DISK_PATH = \"/3DF2DD/LD.ckpt\"\n",
        "    HARDNET_PT = \"/3DF2DD/hardnet8v2/hardnet8v2.pt\"\n",
        "LOG_MESSAGE = \"Final project\"\n",
        "MATCHES_CAP = None\n",
        "DEBUG = True\n",
        "DEBUG = False\n",
        "DEBUG_SCENE = [\"chairs\"]\n",
        "# Longer edge limit of the input image\n",
        "hardnet_res = 1600\n",
        "MODEL_DICT = {\n",
        "    \"Keynet\": {\"enable\":True, \"resize_long_edge_to\": hardnet_res, \"pair_only\": False},\n",
        "    \"GFTT\": {\"enable\": True, \"resize_long_edge_to\": hardnet_res},\n",
        "    \"DoG\": {\"enable\": True, \"resize_long_edge_to\": hardnet_res},\n",
        "    \"Harris\": {\"enable\": True, \"resize_long_edge_to\": hardnet_res},\n",
        "}\n",
        "# Finding fundamental matrix parameters\n",
        "FM_PARAMS = {\"ransacReprojThreshold\": 5, \"confidence\": 0.9999, \"maxIters\": 50000, \"removeOutliers\": True}\n",
        "# Removing a \"match\" if the number of matches is lower than MATCH_FILTER_RATIO*max_num_matches\n",
        "# e.g. img1 and img2 have max 10000 matches with some other images, img2 and img1 only have 99 matches. The matches btw img1 and img2 won't be selected.\n",
        "MATCH_FILTER_RATIO = 0.01\n",
        "# for logging\n",
        "LOG_DICT = dict()\n",
        "LOG_DICT[\"mode\"] = MODE\n",
        "LOG_DICT[\"log_message\"] = LOG_MESSAGE\n",
        "LOG_DICT[\"matches_cap\"] = MATCHES_CAP\n",
        "LOG_DICT[\"debug\"] = DEBUG\n",
        "LOG_DICT[\"debug_scene\"] = DEBUG_SCENE\n",
        "if MODE == \"test\":\n",
        "    DEBUG = False\n",
        "device = torch.device(\"cuda\")\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1326f8",
      "metadata": {
        "papermill": {
          "duration": 0.013773,
          "end_time": "2023-06-22T11:51:28.710917",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.697144",
          "status": "completed"
        },
        "tags": [],
        "id": "0b1326f8"
      },
      "source": [
        "# Getting datadict from project file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc29e83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:28.740588Z",
          "iopub.status.busy": "2023-06-22T11:51:28.740170Z",
          "iopub.status.idle": "2023-06-22T11:51:28.757322Z",
          "shell.execute_reply": "2023-06-22T11:51:28.756181Z"
        },
        "papermill": {
          "duration": 0.034585,
          "end_time": "2023-06-22T11:51:28.759762",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.725177",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc29e83",
        "outputId": "3d0a030f-3c33-46c8-dc4d-b68aed59b039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2cfa01ab573141e4 / 2fa124afd1f74f38 -> 3 images\n",
            "Reconstruction order: \n",
            " --2cfa01ab573141e4 / 2fa124afd1f74f38\n"
          ]
        }
      ],
      "source": [
        "# Getting datadict from csv.\n",
        "if MODE == \"train\":\n",
        "    sample_path = f\"{SRC}/train/train_labels.csv\"\n",
        "else:\n",
        "    sample_path = f\"{SRC}/sample_project.csv\"\n",
        "data_dict = {}\n",
        "with open(sample_path, \"r\") as f:\n",
        "    for i, l in enumerate(f):\n",
        "        # Skipping header.\n",
        "        if l and i > 0:\n",
        "            if MODE == \"train\":\n",
        "                dataset, scene, image, _, _ = l.strip().split(\",\")\n",
        "            else:\n",
        "                image, dataset, scene, _, _ = l.strip().split(\",\")\n",
        "            if dataset not in data_dict:\n",
        "                data_dict[dataset] = {}\n",
        "            if scene not in data_dict[dataset]:\n",
        "                data_dict[dataset][scene] = []\n",
        "            data_dict[dataset][scene].append(image)\n",
        "all_scenes = []\n",
        "scene_len = []\n",
        "for dataset in data_dict:\n",
        "    for scene in data_dict[dataset]:\n",
        "        print(f\"{dataset} / {scene} -> {len(data_dict[dataset][scene])} images\")\n",
        "        if DEBUG and (scene not in DEBUG_SCENE):\n",
        "            continue\n",
        "        all_scenes.append((dataset, scene))\n",
        "        scene_len.append(len(data_dict[dataset][scene]))\n",
        "# sorting all scenes by length from lowest\n",
        "all_scenes = [x for _, x in sorted(zip(scene_len, all_scenes), reverse=True)]\n",
        "# Printing reconst order\n",
        "print(\"Reconstruction order: \")\n",
        "for scene in all_scenes:\n",
        "    print(f\" --{scene[0]} / {scene[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd626769",
      "metadata": {
        "papermill": {
          "duration": 0.013738,
          "end_time": "2023-06-22T11:51:28.787470",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.773732",
          "status": "completed"
        },
        "tags": [],
        "id": "dd626769"
      },
      "source": [
        "# Project Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7478030",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:28.816853Z",
          "iopub.status.busy": "2023-06-22T11:51:28.816488Z",
          "iopub.status.idle": "2023-06-22T11:51:28.826626Z",
          "shell.execute_reply": "2023-06-22T11:51:28.825639Z"
        },
        "papermill": {
          "duration": 0.027368,
          "end_time": "2023-06-22T11:51:28.828764",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.801396",
          "status": "completed"
        },
        "tags": [],
        "id": "a7478030"
      },
      "outputs": [],
      "source": [
        "def arr_to_str(a):\n",
        "    return \";\".join([str(x) for x in a.reshape(-1)])\n",
        "# Function to make a project file.\n",
        "def make_project(out_results, data_dict, mode=\"test\"):\n",
        "    if mode == \"train\":\n",
        "        file_name = \"project_train.csv\"\n",
        "    else:\n",
        "        file_name = \"project.csv\"\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(\"image_path,dataset,scene,rotation_matrix,translation_vector\\n\")\n",
        "        for dataset in data_dict:\n",
        "            if dataset in out_results:\n",
        "                res = out_results[dataset]\n",
        "            else:\n",
        "                res = {}\n",
        "            for scene in data_dict[dataset]:\n",
        "                if scene in res:\n",
        "                    scene_res = res[scene]\n",
        "                else:\n",
        "                    scene_res = {\"R\": {}, \"t\": {}}\n",
        "                for image in data_dict[dataset][scene]:\n",
        "                    if image in scene_res:\n",
        "                        print(image)\n",
        "                        R = scene_res[image][\"R\"].reshape(-1)\n",
        "                        T = scene_res[image][\"t\"].reshape(-1)\n",
        "                    else:\n",
        "                        R = np.eye(3).reshape(-1)\n",
        "                        T = np.zeros((3))\n",
        "                    f.write(\n",
        "                        f\"{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85650c6",
      "metadata": {
        "papermill": {
          "duration": 0.013956,
          "end_time": "2023-06-22T11:51:28.856564",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.842608",
          "status": "completed"
        },
        "tags": [],
        "id": "d85650c6"
      },
      "source": [
        "# Image Loading and Resizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c62e2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:28.886754Z",
          "iopub.status.busy": "2023-06-22T11:51:28.886378Z",
          "iopub.status.idle": "2023-06-22T11:51:28.900224Z",
          "shell.execute_reply": "2023-06-22T11:51:28.899081Z"
        },
        "papermill": {
          "duration": 0.031998,
          "end_time": "2023-06-22T11:51:28.902778",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.870780",
          "status": "completed"
        },
        "tags": [],
        "id": "a5c62e2b"
      },
      "outputs": [],
      "source": [
        "def load_torch_image(fname, device=torch.device(\"cpu\")):\n",
        "    img = K.image_to_tensor(cv2.imread(fname), False).float() / 255.0\n",
        "    img = K.color.bgr_to_rgb(img.to(device))\n",
        "    return img\n",
        "def resize_torch_image(\n",
        "    timg, resize_long_edge_to=None, align=None, disable_enlarge=True\n",
        "):\n",
        "    h, w = timg.shape[2:]\n",
        "    raw_size = torch.tensor(timg.shape[2:])\n",
        "    if resize_long_edge_to is None:\n",
        "        scale = 1\n",
        "    else:\n",
        "        scale = float(resize_long_edge_to) / float(max(raw_size[0], raw_size[1]))\n",
        "    if disable_enlarge:\n",
        "        scale = min(scale, 1)\n",
        "    h_resized = int(h * scale)\n",
        "    w_resized = int(w * scale)\n",
        "    if align is not None:\n",
        "        assert align > 0\n",
        "        h_resized = h_resized - h_resized % align\n",
        "        w_resized = w_resized - w_resized % align\n",
        "    scale_h = h_resized / h\n",
        "    scale_w = w_resized / w\n",
        "    timg_resized = K.geometry.resize(timg, (h_resized, w_resized), antialias = True)\n",
        "    return timg_resized, scale_h, scale_w\n",
        "def get_roi_image(timg, roi):\n",
        "    min_h = int(roi[\"roi_min_h\"])\n",
        "    min_w = int(roi[\"roi_min_w\"])\n",
        "    max_h = int(roi[\"roi_max_h\"])\n",
        "    max_w = int(roi[\"roi_max_w\"])\n",
        "    roi_img = timg[:, :, min_h:max_h, min_w:max_w]\n",
        "    roi_w_scale = (max_w - min_w) / timg.shape[3]\n",
        "    roi_h_scale = (max_h - min_h) / timg.shape[2]\n",
        "    return roi_img, min_h, min_w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abe7c7f",
      "metadata": {
        "papermill": {
          "duration": 0.013281,
          "end_time": "2023-06-22T11:51:28.929869",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.916588",
          "status": "completed"
        },
        "tags": [],
        "id": "2abe7c7f"
      },
      "source": [
        "# Visualization Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9781e055",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:28.960217Z",
          "iopub.status.busy": "2023-06-22T11:51:28.959853Z",
          "iopub.status.idle": "2023-06-22T11:51:28.978224Z",
          "shell.execute_reply": "2023-06-22T11:51:28.977222Z"
        },
        "papermill": {
          "duration": 0.036556,
          "end_time": "2023-06-22T11:51:28.980666",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.944110",
          "status": "completed"
        },
        "tags": [],
        "id": "9781e055"
      },
      "outputs": [],
      "source": [
        "# Visualzation block\n",
        "def draw_keypoints(img, keypoints, color=(0, 255, 0)):\n",
        "    max_edge = max(img.shape[0], img.shape[1])\n",
        "    good_radius = 4\n",
        "    for kp in keypoints:\n",
        "        x, y = kp\n",
        "        cv2.circle(img, (int(x), int(y)), color=color, radius=good_radius, thickness=-1)\n",
        "def draw_roi(img, roi, color=(0, 255, 255)):\n",
        "    x1, y1, x2, y2 = (\n",
        "        roi[\"roi_min_w\"],\n",
        "        roi[\"roi_min_h\"],\n",
        "        roi[\"roi_max_w\"],\n",
        "        roi[\"roi_max_h\"],\n",
        "    )\n",
        "    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color=color, thickness=2)\n",
        "def plot_images_with_keypoints(fname1, fname2, kpts1, kpts2, matches, rois=None):\n",
        "    print(fname1, fname2)\n",
        "    # Drawing keypoints on the images\n",
        "    image1 = cv2.imread(fname1)\n",
        "    image2 = cv2.imread(fname2)\n",
        "    print(image1.shape, image2.shape)\n",
        "    draw_keypoints(image1, kpts1)\n",
        "    draw_keypoints(image2, kpts2)\n",
        "    if rois is not None:\n",
        "        draw_roi(image1, rois[0])\n",
        "        draw_roi(image2, rois[1])\n",
        "    print(image1.shape, image2.shape)\n",
        "    print(\"Number of matches:\", len(matches))\n",
        "    print(\"Number of keypoints:\", len(kpts1), len(kpts2))\n",
        "    # printing the first match\n",
        "    print(matches[0])\n",
        "    # Resizing image1 and image2 to have the same smaller height\n",
        "    display_h = 840\n",
        "    h1, w1 = image1.shape[:2]\n",
        "    h2, w2 = image2.shape[:2]\n",
        "    # new_h = min(h1, h2)\n",
        "    scale1 = display_h / h1\n",
        "    scale2 = display_h / h2\n",
        "    new_w1 = int(w1 * scale1)\n",
        "    new_w2 = int(w2 * scale2)\n",
        "    image1 = cv2.resize(image1, (new_w1, display_h))\n",
        "    image2 = cv2.resize(image2, (new_w2, display_h))\n",
        "    # Making a new image by horizontally concatenating the two images\n",
        "    concatenated_img = cv2.hconcat([image1, image2])\n",
        "    # Drawing lines between the matching keypoints\n",
        "    for match in matches:\n",
        "        img1_idx = match[0]\n",
        "        img2_idx = match[1]\n",
        "        (x1, y1) = kpts1[img1_idx] * scale1\n",
        "        (x2, y2) = kpts2[img2_idx] * scale2\n",
        "        pt1 = (int(x1), int(y1))\n",
        "        pt2 = (int(x2) + image1.shape[1], int(y2))\n",
        "        cv2.line(concatenated_img, pt1, pt2, (0, 0, 255), 2)\n",
        "    # Plotting the concatenated image\n",
        "    plt.figure(figsize=(20, 12))\n",
        "    plt.imshow(cv2.cvtColor(concatenated_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4355e7",
      "metadata": {
        "papermill": {
          "duration": 0.013642,
          "end_time": "2023-06-22T11:51:29.008889",
          "exception": false,
          "start_time": "2023-06-22T11:51:28.995247",
          "status": "completed"
        },
        "tags": [],
        "id": "ca4355e7"
      },
      "source": [
        "# Colmap database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a282f8",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.037968Z",
          "iopub.status.busy": "2023-06-22T11:51:29.037610Z",
          "iopub.status.idle": "2023-06-22T11:51:29.071161Z",
          "shell.execute_reply": "2023-06-22T11:51:29.070136Z"
        },
        "papermill": {
          "duration": 0.051246,
          "end_time": "2023-06-22T11:51:29.073943",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.022697",
          "status": "completed"
        },
        "tags": [],
        "id": "d3a282f8"
      },
      "outputs": [],
      "source": [
        "# Code to manipulate a colmap database.\n",
        "# This script is based on an original implementation by True Price.\n",
        "import sys\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "IS_PYTHON3 = sys.version_info[0] >= 3\n",
        "MAX_IMAGE_ID = 2**31 - 1\n",
        "# It was said:\n",
        "CREATE_CAMERAS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS cameras (\n",
        "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "    model INTEGER NOT NULL,\n",
        "    width INTEGER NOT NULL,\n",
        "    height INTEGER NOT NULL,\n",
        "    params BLOB,\n",
        "    prior_focal_length INTEGER NOT NULL)\"\"\"\n",
        "# was said.\n",
        "# It was said:\n",
        "CREATE_DESCRIPTORS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS descriptors (\n",
        "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\"\"\"\n",
        "# was said.\n",
        "# It was said:\n",
        "CREATE_IMAGES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS images (\n",
        "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "    name TEXT NOT NULL UNIQUE,\n",
        "    camera_id INTEGER NOT NULL,\n",
        "    prior_qw REAL,\n",
        "    prior_qx REAL,\n",
        "    prior_qy REAL,\n",
        "    prior_qz REAL,\n",
        "    prior_tx REAL,\n",
        "    prior_ty REAL,\n",
        "    prior_tz REAL,\n",
        "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {}),\n",
        "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))\n",
        "\"\"\".format(# was said.\n",
        "    MAX_IMAGE_ID\n",
        ")\n",
        "# It was said:\n",
        "CREATE_TWO_VIEW_GEOMETRIES_TABLE = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
        "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    config INTEGER NOT NULL,\n",
        "    F BLOB,\n",
        "    E BLOB,\n",
        "    H BLOB)\n",
        "\"\"\"\n",
        "# was said.\n",
        "# It was said:\n",
        "CREATE_KEYPOINTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS keypoints (\n",
        "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\n",
        "\"\"\"\n",
        "# was said.\n",
        "# It was said:\n",
        "CREATE_MATCHES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
        "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB)\"\"\"\n",
        "# was said.\n",
        "# It was said:\n",
        "CREATE_NAME_INDEX = \"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\"\n",
        "# was said.\n",
        "CREATE_ALL = \"; \".join( # was said.\n",
        "    [\n",
        "        # It was said:\n",
        "        CREATE_CAMERAS_TABLE,\n",
        "        CREATE_IMAGES_TABLE,\n",
        "        CREATE_KEYPOINTS_TABLE,\n",
        "        CREATE_DESCRIPTORS_TABLE,\n",
        "        CREATE_MATCHES_TABLE,\n",
        "        CREATE_TWO_VIEW_GEOMETRIES_TABLE,\n",
        "        CREATE_NAME_INDEX,\n",
        "        # was said.\n",
        "    ]\n",
        ")\n",
        "def image_ids_to_pair_id(image_id1, image_id2):\n",
        "    if image_id1 > image_id2:\n",
        "        image_id1, image_id2 = image_id2, image_id1\n",
        "    return image_id1 * MAX_IMAGE_ID + image_id2\n",
        "def pair_id_to_image_ids(pair_id):\n",
        "    image_id2 = pair_id % MAX_IMAGE_ID\n",
        "    image_id1 = (pair_id - image_id2) / MAX_IMAGE_ID\n",
        "    return image_id1, image_id2\n",
        "def array_to_blob(array):\n",
        "    if IS_PYTHON3:\n",
        "        return array.tostring()\n",
        "    else:\n",
        "        return np.getbuffer(array)\n",
        "def blob_to_array(blob, dtype, shape=(-1,)):\n",
        "    if IS_PYTHON3:\n",
        "        return np.fromstring(blob, dtype=dtype).reshape(*shape)\n",
        "    else:\n",
        "        return np.frombuffer(blob, dtype=dtype).reshape(*shape)\n",
        "class COLMAPDatabase(sqlite3.Connection):\n",
        "    @staticmethod\n",
        "    def connect(database_path):\n",
        "        return sqlite3.connect(database_path, factory=COLMAPDatabase)\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
        "# It was said:\n",
        "        self.create_tables = lambda: self.executescript(CREATE_ALL)\n",
        "        self.create_cameras_table = lambda: self.executescript(CREATE_CAMERAS_TABLE)\n",
        "        self.create_descriptors_table = lambda: self.executescript(\n",
        "            CREATE_DESCRIPTORS_TABLE\n",
        "        )\n",
        "        self.create_images_table = lambda: self.executescript(CREATE_IMAGES_TABLE)\n",
        "        self.create_two_view_geometries_table = lambda: self.executescript(\n",
        "            CREATE_TWO_VIEW_GEOMETRIES_TABLE\n",
        "        )\n",
        "        self.create_keypoints_table = lambda: self.executescript(CREATE_KEYPOINTS_TABLE)\n",
        "        self.create_matches_table = lambda: self.executescript(CREATE_MATCHES_TABLE)\n",
        "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX)\n",
        "# was said.\n",
        "    def add_camera(\n",
        "        self, model, width, height, params, prior_focal_length=False, camera_id=None\n",
        "    ):\n",
        "        params = np.asarray(params, np.float64)\n",
        "        cursor = self.execute(\n",
        "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (\n",
        "                camera_id,\n",
        "                model,\n",
        "                width,\n",
        "                height,\n",
        "                array_to_blob(params),\n",
        "                prior_focal_length,\n",
        "            ),\n",
        "        )\n",
        "        return cursor.lastrowid\n",
        "    def add_image(\n",
        "        self, name, camera_id, prior_q=np.zeros(4), prior_t=np.zeros(3), image_id=None\n",
        "    ):\n",
        "        cursor = self.execute(\n",
        "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (\n",
        "                image_id,\n",
        "                name,\n",
        "                camera_id,\n",
        "                prior_q[0],\n",
        "                prior_q[1],\n",
        "                prior_q[2],\n",
        "                prior_q[3],\n",
        "                prior_t[0],\n",
        "                prior_t[1],\n",
        "                prior_t[2],\n",
        "            ),\n",
        "        )\n",
        "        return cursor.lastrowid\n",
        "    def add_keypoints(self, image_id, keypoints):\n",
        "        assert len(keypoints.shape) == 2\n",
        "        assert keypoints.shape[1] in [2, 4, 6]\n",
        "        keypoints = np.asarray(keypoints, np.float32)\n",
        "        self.execute(\n",
        "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "            (image_id,) + keypoints.shape + (array_to_blob(keypoints),),\n",
        "        )\n",
        "    def add_descriptors(self, image_id, descriptors):\n",
        "        descriptors = np.ascontiguousarray(descriptors, np.uint8)\n",
        "        self.execute(\n",
        "            \"INSERT INTO descriptors VALUES (?, ?, ?, ?)\",\n",
        "            (image_id,) + descriptors.shape + (array_to_blob(descriptors),),\n",
        "        )\n",
        "    def add_matches(self, image_id1, image_id2, matches):\n",
        "        assert len(matches.shape) == 2\n",
        "        assert matches.shape[1] == 2\n",
        "        if image_id1 > image_id2:\n",
        "            matches = matches[:, ::-1]\n",
        "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
        "        matches = np.asarray(matches, np.uint32)\n",
        "        self.execute(\n",
        "            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
        "            (pair_id,) + matches.shape + (array_to_blob(matches),),\n",
        "        )\n",
        "    def add_two_view_geometry(\n",
        "        self,\n",
        "        image_id1,\n",
        "        image_id2,\n",
        "        matches,\n",
        "        F=np.eye(3),\n",
        "        E=np.eye(3),\n",
        "        H=np.eye(3),\n",
        "        config=2,\n",
        "    ):\n",
        "        assert len(matches.shape) == 2\n",
        "        assert matches.shape[1] == 2\n",
        "        if image_id1 > image_id2:\n",
        "            matches = matches[:, ::-1]\n",
        "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
        "        matches = np.asarray(matches, np.uint32)\n",
        "        F = np.asarray(F, dtype=np.float64)\n",
        "        E = np.asarray(E, dtype=np.float64)\n",
        "        H = np.asarray(H, dtype=np.float64)\n",
        "        self.execute(\n",
        "            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (pair_id,)\n",
        "            + matches.shape\n",
        "            + (\n",
        "                array_to_blob(matches),\n",
        "                config,\n",
        "                array_to_blob(F),\n",
        "                array_to_blob(E),\n",
        "                array_to_blob(H),\n",
        "            ),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e182a2e8",
      "metadata": {
        "papermill": {
          "duration": 0.013418,
          "end_time": "2023-06-22T11:51:29.101310",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.087892",
          "status": "completed"
        },
        "tags": [],
        "id": "e182a2e8"
      },
      "source": [
        "# DB operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be61c394",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.130550Z",
          "iopub.status.busy": "2023-06-22T11:51:29.130161Z",
          "iopub.status.idle": "2023-06-22T11:51:29.151491Z",
          "shell.execute_reply": "2023-06-22T11:51:29.150352Z"
        },
        "papermill": {
          "duration": 0.038884,
          "end_time": "2023-06-22T11:51:29.153835",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.114951",
          "status": "completed"
        },
        "tags": [],
        "id": "be61c394"
      },
      "outputs": [],
      "source": [
        "import os, argparse, h5py, warnings\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ExifTags\n",
        "def get_focal(image_path, err_on_default=False):\n",
        "    image = Image.open(image_path)\n",
        "    max_size = max(image.size)\n",
        "    exif = image.getexif()\n",
        "    # Modified to add exif_ifd to exif dict\n",
        "    exif_ifd = exif.get_ifd(0x8769)\n",
        "    exif.update(exif_ifd)\n",
        "    focal = None\n",
        "    is_from_exif = False\n",
        "    if exif is not None:\n",
        "        focal_35mm = None\n",
        "        for tag, value in exif.items():\n",
        "            focal_35mm = None\n",
        "            if ExifTags.TAGS.get(tag, None) == \"FocalLengthIn35mmFilm\":\n",
        "                focal_35mm = float(value)\n",
        "                is_from_exif = True\n",
        "                break\n",
        "        if focal_35mm is not None:\n",
        "            focal = focal_35mm / 35.0 * max_size\n",
        "    if focal is None:\n",
        "        if err_on_default:\n",
        "            raise RuntimeError(\"Failed to find focal length\")\n",
        "        # failed to find it in exif, use prior\n",
        "        FOCAL_PRIOR = 1.2\n",
        "        focal = FOCAL_PRIOR * max_size\n",
        "    # Modified to return a bool indicating if the focal length is from exif\n",
        "    return focal, is_from_exif\n",
        "def make_camera(db, image_path, camera_model):\n",
        "    image = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "    focal, is_from_exif = get_focal(image_path)\n",
        "    if camera_model == \"simple-pinhole\":\n",
        "        model = 0  # simple pinhole\n",
        "        param_arr = np.array([focal, width / 2, height / 2])\n",
        "    if camera_model == \"pinhole\":\n",
        "        model = 1  # pinhole\n",
        "        param_arr = np.array([focal, focal, width / 2, height / 2])\n",
        "    elif camera_model == \"simple-radial\":\n",
        "        model = 2  # simple radial\n",
        "        param_arr = np.array([focal, width / 2, height / 2, 0.1])\n",
        "    elif camera_model == \"opencv\":\n",
        "        model = 4  # opencv\n",
        "        param_arr = np.array([focal, focal, width / 2, height / 2, 0.0, 0.0, 0.0, 0.0])\n",
        "    # Modified to set prior_focal_length if the focal length is from exif\n",
        "    return db.add_camera(\n",
        "        model, width, height, param_arr, prior_focal_length=is_from_exif\n",
        "    )\n",
        "def add_kpts_matches(db, img_dir, kpts, matches, fms = None):\n",
        "    fname_to_id = {}\n",
        "    # Adding keypoints\n",
        "    for filename in tqdm(kpts):\n",
        "        path = os.path.join(img_dir, filename)\n",
        "        camera_model = \"simple-radial\"\n",
        "        camera_id = make_camera(db, path, camera_model)\n",
        "        image_id = db.add_image(filename, camera_id)\n",
        "        fname_to_id[filename] = image_id\n",
        "        db.add_keypoints(image_id, kpts[filename])\n",
        "        n_keys = len(matches)\n",
        "        n_total = (n_keys * (n_keys - 1)) // 2\n",
        "    # Adding matches\n",
        "    added = set()\n",
        "    with tqdm(total=n_total) as pbar:\n",
        "        for key1 in matches:\n",
        "            for key2 in matches[key1]:\n",
        "                id_1 = fname_to_id[key1]\n",
        "                id_2 = fname_to_id[key2]\n",
        "                pair_id = image_ids_to_pair_id(id_1, id_2)\n",
        "                if pair_id in added:\n",
        "                    warnings.warn(f\"Pair {pair_id} ({id_1}, {id_2}) already added!\")\n",
        "                    continue\n",
        "                db.add_matches(id_1, id_2, matches[key1][key2])\n",
        "                added.add(pair_id)\n",
        "                pbar.update(1)\n",
        "                if fms is not None:\n",
        "                    db.add_two_view_geometry(id_1, id_2, matches[key1][key2], fms[key1][key2], np.eye(3), np.eye(3))\n",
        "    db.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c31bff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.184498Z",
          "iopub.status.busy": "2023-06-22T11:51:29.183487Z",
          "iopub.status.idle": "2023-06-22T11:51:29.190830Z",
          "shell.execute_reply": "2023-06-22T11:51:29.189872Z"
        },
        "papermill": {
          "duration": 0.025311,
          "end_time": "2023-06-22T11:51:29.193400",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.168089",
          "status": "completed"
        },
        "tags": [],
        "id": "55c31bff"
      },
      "outputs": [],
      "source": [
        "def get_unique_idxs(A, dim=0):\n",
        "    unique, idx, counts = torch.unique(\n",
        "        A, dim=dim, sorted=True, return_inverse=True, return_counts=True\n",
        "    )\n",
        "    _, ind_sorted = torch.sort(idx, stable=True)\n",
        "    cum_sum = counts.cumsum(0)\n",
        "    cum_sum = torch.cat((torch.tensor([0], device=cum_sum.device), cum_sum[:-1]))\n",
        "    first_indices = ind_sorted[cum_sum]\n",
        "    return first_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "043fef99",
      "metadata": {
        "papermill": {
          "duration": 0.013779,
          "end_time": "2023-06-22T11:51:29.221302",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.207523",
          "status": "completed"
        },
        "tags": [],
        "id": "043fef99"
      },
      "source": [
        "# AffNetHardNet Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f94c51",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.251662Z",
          "iopub.status.busy": "2023-06-22T11:51:29.250731Z",
          "iopub.status.idle": "2023-06-22T11:51:29.267566Z",
          "shell.execute_reply": "2023-06-22T11:51:29.266581Z"
        },
        "papermill": {
          "duration": 0.034898,
          "end_time": "2023-06-22T11:51:29.270031",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.235133",
          "status": "completed"
        },
        "tags": [],
        "id": "02f94c51"
      },
      "outputs": [],
      "source": [
        "# Making kornia local features loading w/o internet\n",
        "class AffNetHardNet(KF.LocalFeature):\n",
        "    \"\"\"Convenience module, which implements KeyNet detector + AffNet + HardNet descriptor.\n",
        "    .. image:: _static/img/keynet_affnet.jpg\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features: int = 5000,\n",
        "        upright: bool = False,\n",
        "        device=torch.device(\"cpu\"),\n",
        "        scale_laf: float = 1.0,\n",
        "        detector = \"keynet\"\n",
        "    ):\n",
        "        detector_options = [\"keynet\", \"GFTT\", \"Hessian\", \"Harris\", \"DoG\"]\n",
        "        if detector not in detector_options:\n",
        "            raise ValueError(\"Detector required to be one of {}\".format(detector_options))\n",
        "        ori_module = (\n",
        "            KF.PassLAF()\n",
        "            if upright\n",
        "            else KF.LAFOrienter(angle_detector=KF.OriNet(False)).eval()\n",
        "        )\n",
        "        if not upright:\n",
        "            weights = torch.load(os.path.join(MODEL_DIR, \"OriNet.pth\"))[\"state_dict\"]\n",
        "            ori_module.angle_detector.load_state_dict(weights)\n",
        "        config = {\n",
        "            # Extraction Parameters\n",
        "            \"nms_size\": 15,\n",
        "            \"pyramid_levels\": 4,\n",
        "            \"up_levels\": 1,\n",
        "            \"scale_factor_levels\": math.sqrt(2),\n",
        "            \"s_mult\": 22.0,\n",
        "        }\n",
        "        if detector == \"keynet\":\n",
        "            detector = KF.KeyNetDetector(\n",
        "            False,\n",
        "            num_features=num_features,\n",
        "            ori_module=ori_module,\n",
        "            aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
        "            ).to(device)\n",
        "            kn_weights = torch.load(os.path.join(MODEL_DIR, \"keynet_pytorch.pth\"))[\n",
        "            \"state_dict\"\n",
        "            ]\n",
        "            detector.model.load_state_dict(kn_weights)\n",
        "        elif detector == \"GFTT\":\n",
        "            detector = KF.MultiResolutionDetector(\n",
        "                KF.CornerGFTT(),\n",
        "                num_features=num_features,\n",
        "                config=config,\n",
        "                ori_module=ori_module,\n",
        "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
        "            ).to(device)\n",
        "        elif detector == \"Harris\":\n",
        "            detector = KF.MultiResolutionDetector(\n",
        "                KF.CornerHarris(0.04),\n",
        "                num_features=num_features,\n",
        "                config=config,\n",
        "                ori_module=ori_module,\n",
        "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
        "            ).to(device)\n",
        "        elif detector == \"DoG\":\n",
        "            detector = KF.MultiResolutionDetector(\n",
        "                KF.BlobDoGSingle(),\n",
        "                num_features=num_features,\n",
        "                config=config,\n",
        "                ori_module=ori_module,\n",
        "                aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n",
        "            ).to(device)\n",
        "        affnet_weights = torch.load(os.path.join(MODEL_DIR, \"AffNet.pth\"))[\"state_dict\"]\n",
        "        detector.aff.load_state_dict(affnet_weights)\n",
        "        # hardnet = KF.HardNet(False).eval()\n",
        "        # hn_weights = torch.load(os.path.join(MODEL_DIR, \"HardNetLib.pth\"))[\"state_dict\"]\n",
        "        # hardnet.load_state_dict(hn_weights)\n",
        "        # descriptor = KF.LAFDescriptor(\n",
        "        #     hardnet, patch_size=32, grayscale_descriptor=True\n",
        "        # ).to(device)\n",
        "        hardnet8 = KF.HardNet8(False).eval()\n",
        "        hn8_weights = torch.load(HARDNET_PT)\n",
        "        hardnet8.load_state_dict(hn8_weights)\n",
        "        descriptor = KF.LAFDescriptor(\n",
        "            hardnet8, patch_size=32, grayscale_descriptor=True\n",
        "        ).to(device)\n",
        "        super().__init__(detector, descriptor, scale_laf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfaac9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.299486Z",
          "iopub.status.busy": "2023-06-22T11:51:29.299110Z",
          "iopub.status.idle": "2023-06-22T11:51:29.312853Z",
          "shell.execute_reply": "2023-06-22T11:51:29.311792Z"
        },
        "papermill": {
          "duration": 0.031228,
          "end_time": "2023-06-22T11:51:29.315198",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.283970",
          "status": "completed"
        },
        "tags": [],
        "id": "fdfaac9a"
      },
      "outputs": [],
      "source": [
        "def get_unique_matches(f_match_kpts):\n",
        "    kpts = defaultdict(list)\n",
        "    match_indexes = defaultdict(dict)\n",
        "    total_kpts = defaultdict(int)\n",
        "    for key1 in f_match_kpts:\n",
        "        for key2 in f_match_kpts[key1]:\n",
        "            matches = f_match_kpts[key1][key2]\n",
        "            kpts[key1].append(matches[:, :2])\n",
        "            kpts[key2].append(matches[:, 2:])\n",
        "            current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
        "            current_match[:, 0] += total_kpts[key1]\n",
        "            current_match[:, 1] += total_kpts[key2]\n",
        "            total_kpts[key1] += len(matches)\n",
        "            total_kpts[key2] += len(matches)\n",
        "            match_indexes[key1][key2] = current_match\n",
        "    for key in kpts:\n",
        "        kpts[key] = np.round(np.concatenate(kpts[key], axis=0))\n",
        "    unique_kpts = {}\n",
        "    unique_match_idxs = {}\n",
        "    out_match = defaultdict(dict)\n",
        "    for key in kpts.keys():\n",
        "        uniq_kps, uniq_reverse_idxs = torch.unique(\n",
        "            torch.from_numpy(kpts[key]), dim=0, return_inverse=True\n",
        "        )\n",
        "        unique_match_idxs[key] = uniq_reverse_idxs\n",
        "        unique_kpts[key] = uniq_kps.numpy()\n",
        "    for key1 in match_indexes:\n",
        "        for key2 in match_indexes[key1]:\n",
        "            m2 = deepcopy(match_indexes[key1][key2])\n",
        "            m2[:, 0] = unique_match_idxs[key1][m2[:, 0]]\n",
        "            m2[:, 1] = unique_match_idxs[key2][m2[:, 1]]\n",
        "            mkpts = np.concatenate(\n",
        "                [\n",
        "                    unique_kpts[key1][m2[:, 0]],\n",
        "                    unique_kpts[key2][m2[:, 1]],\n",
        "                ],\n",
        "                axis=1,\n",
        "            )\n",
        "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
        "            m2_semiclean = m2[unique_idxs_current]\n",
        "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
        "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
        "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
        "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
        "            out_match[key1][key2] = m2_semiclean2.numpy()\n",
        "    return unique_kpts, out_match"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0468c3",
      "metadata": {
        "papermill": {
          "duration": 0.014038,
          "end_time": "2023-06-22T11:51:29.343020",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.328982",
          "status": "completed"
        },
        "tags": [],
        "id": "9c0468c3"
      },
      "source": [
        "# Scene feature detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8040a198",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.373378Z",
          "iopub.status.busy": "2023-06-22T11:51:29.372955Z",
          "iopub.status.idle": "2023-06-22T11:51:29.387199Z",
          "shell.execute_reply": "2023-06-22T11:51:29.386165Z"
        },
        "papermill": {
          "duration": 0.032126,
          "end_time": "2023-06-22T11:51:29.389712",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.357586",
          "status": "completed"
        },
        "tags": [],
        "id": "8040a198"
      },
      "outputs": [],
      "source": [
        "class AffNetHardNetDetector:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        device=torch.device(\"cuda\"),\n",
        "        resize_long_edge_to=600,\n",
        "        matcher=\"adalam\",\n",
        "        min_matches=15,\n",
        "        rgb_input = False\n",
        "    ):\n",
        "        self.rgb_input = rgb_input\n",
        "        print(\"Init AffNetHardNetDetector\")\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.resize_long_edge_to = resize_long_edge_to\n",
        "        print(\"Longer edge will be resized to\", self.resize_long_edge_to)\n",
        "    def detect_features(self, img_fnames):\n",
        "        f_lafs = dict()\n",
        "        f_descs = dict()\n",
        "        f_kpts = dict()\n",
        "        f_raw_size = dict()\n",
        "        f_matches = dict()\n",
        "        # Getting features\n",
        "        print(\"Detecting AffNetHardNet features\")\n",
        "        for img_path in tqdm(img_fnames):\n",
        "            img_fname = img_path.split(\"/\")[-1]\n",
        "            key = img_fname\n",
        "            f_matches[key] = dict()\n",
        "            with torch.inference_mode():\n",
        "                timg = load_torch_image(img_path, device=device)\n",
        "                raw_size = torch.tensor(timg.shape[2:])\n",
        "                timg_resized, h_scale, w_scale = resize_torch_image(\n",
        "                    timg, self.resize_long_edge_to, disable_enlarge=True\n",
        "                )\n",
        "                if self.rgb_input:\n",
        "                    lafs, resps, descs = self.model(timg_resized)\n",
        "                else:\n",
        "                    lafs, resps, descs = self.model(K.color.rgb_to_grayscale(timg_resized))\n",
        "                # Recovering scale?\n",
        "                lafs[:, :, 0, :] *= 1 / w_scale\n",
        "                lafs[:, :, 1, :] *= 1 / h_scale\n",
        "                desc_dim = descs.shape[-1]\n",
        "                # Moving keypoints to cpu for later colmap operations\n",
        "                kpts = KF.get_laf_center(lafs).reshape(-1, 2).detach().cpu().numpy()\n",
        "                descs = descs.reshape(-1, desc_dim).detach()\n",
        "                f_lafs[key] = lafs.detach()\n",
        "                f_kpts[key] = kpts\n",
        "                f_descs[key] = descs\n",
        "                f_raw_size[key] = raw_size\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        return f_lafs, f_kpts, f_descs, f_raw_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afd68d5f",
      "metadata": {
        "papermill": {
          "duration": 0.013225,
          "end_time": "2023-06-22T11:51:29.417202",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.403977",
          "status": "completed"
        },
        "tags": [],
        "id": "afd68d5f"
      },
      "source": [
        "## Scene LAF matcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffddfed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.447761Z",
          "iopub.status.busy": "2023-06-22T11:51:29.447052Z",
          "iopub.status.idle": "2023-06-22T11:51:29.468826Z",
          "shell.execute_reply": "2023-06-22T11:51:29.467758Z"
        },
        "papermill": {
          "duration": 0.040075,
          "end_time": "2023-06-22T11:51:29.471381",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.431306",
          "status": "completed"
        },
        "tags": [],
        "id": "4ffddfed"
      },
      "outputs": [],
      "source": [
        "class LafMatcher:\n",
        "    def __init__(self, min_matches=15, device=\"cuda\", matcher=\"adalam\"):\n",
        "        self.adalam_config = KF.adalam.get_adalam_default_config()\n",
        "        self.adalam_config[\"force_seed_mnn\"] = True\n",
        "        self.adalam_config[\"search_expansion\"] = 16\n",
        "        self.adalam_config[\"ransac_iters\"] = 256\n",
        "        self.adalam_config[\"device\"] = device\n",
        "        # self.adalam_config[\"orientation_difference_threshold\"] = None\n",
        "        # self.adalam_config['scale_rate_threshold'] = None\n",
        "        self.min_matches = min_matches\n",
        "        self.matcher = matcher\n",
        "    def match(self, img_fnames, f_lafs, f_kpts, f_descs, f_raw_size, get_roi = False):\n",
        "        index_pairs = dict()\n",
        "        num_imgs = len(img_fnames)\n",
        "        print(\"Matching to get index pairs\")\n",
        "        pair_count = 0\n",
        "        f_matches = defaultdict(dict)\n",
        "        f_rois = defaultdict(dict)\n",
        "        for idx1 in tqdm(range(num_imgs - 1)):\n",
        "            index_pairs[idx1] = []\n",
        "            for idx2 in range(idx1 + 1, num_imgs):\n",
        "                fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "                key1, key2 = fname1.split(\"/\")[-1], fname2.split(\"/\")[-1]\n",
        "                lafs1 = f_lafs[key1]\n",
        "                lafs2 = f_lafs[key2]\n",
        "                desc1 = f_descs[key1]\n",
        "                desc2 = f_descs[key2]\n",
        "                if self.matcher == \"adalam\":\n",
        "                    hw1, hw2 = f_raw_size[key1], f_raw_size[key2]\n",
        "                    dists, idxs = KF.match_adalam(\n",
        "                        desc1,\n",
        "                        desc2,\n",
        "                        lafs1,\n",
        "                        lafs2,  # Adalam takes into account also geometric information\n",
        "                        hw1=hw1,\n",
        "                        hw2=hw2,\n",
        "                        config=self.adalam_config,\n",
        "                    )  # It was said: (Adalam also benefits from knowing image size)\n",
        "                else:\n",
        "                    dists, idxs = KF.match_smnn(desc1, desc2, 0.98)\n",
        "                if dists.mean().cpu().numpy() < 0.5:\n",
        "                    first_indices = get_unique_idxs(idxs[:, 1])\n",
        "                    idxs = idxs[first_indices]\n",
        "                    dists = dists[first_indices]\n",
        "                    n_matches = len(idxs)\n",
        "                    if n_matches >= self.min_matches:\n",
        "                        pair_count += 1\n",
        "                        index_pairs[idx1].append(\n",
        "                            [idx2, dists.mean().cpu().numpy().item(), n_matches]\n",
        "                        )\n",
        "                        f_matches[key1][key2] = (\n",
        "                            idxs.detach().cpu().numpy().reshape(-1, 2)\n",
        "                        )\n",
        "                        # Computing ROI\n",
        "                        if get_roi:\n",
        "                            mkpts1 = f_kpts[key1][idxs.cpu().numpy()[:, 0]]\n",
        "                            mkpts2 = f_kpts[key2][idxs.cpu().numpy()[:, 1]]\n",
        "                            roi_min_w_1, roi_max_w_1 = np.percentile(mkpts1[:, 0], [5, 95])\n",
        "                            roi_min_h_1, roi_max_h_1 = np.percentile(mkpts1[:, 1], [5, 95])\n",
        "                            roi_area_1 = (roi_max_w_1 - roi_min_w_1) * (\n",
        "                                roi_max_h_1 - roi_min_h_1\n",
        "                            )\n",
        "                            roi1 = {\n",
        "                                \"roi_min_w\": roi_min_w_1,\n",
        "                                \"roi_min_h\": roi_min_h_1,\n",
        "                                \"roi_max_w\": roi_max_w_1,\n",
        "                                \"roi_max_h\": roi_max_h_1,\n",
        "                                \"area\": roi_area_1,\n",
        "                            }\n",
        "                            roi_min_w_2, roi_max_w_2 = np.percentile(mkpts2[:, 0], [5, 95])\n",
        "                            roi_min_h_2, roi_max_h_2 = np.percentile(mkpts2[:, 1], [5, 95])\n",
        "                            roi_area_2 = (roi_max_w_2 - roi_min_w_2) * (\n",
        "                                roi_max_h_2 - roi_min_h_2\n",
        "                            )\n",
        "                            roi2 = {\n",
        "                                \"roi_min_w\": roi_min_w_2,\n",
        "                                \"roi_min_h\": roi_min_h_2,\n",
        "                                \"roi_max_w\": roi_max_w_2,\n",
        "                                \"roi_max_h\": roi_max_h_2,\n",
        "                                \"area\": roi_area_2,\n",
        "                            }\n",
        "                            f_rois[key1][key2] = [roi1, roi2]\n",
        "        print(f\" Get {pair_count} from {int(num_imgs * (num_imgs-1)/2)} possible pairs\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        return index_pairs, f_kpts, f_matches, f_rois"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709e431b",
      "metadata": {
        "papermill": {
          "duration": 0.013414,
          "end_time": "2023-06-22T11:51:29.498700",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.485286",
          "status": "completed"
        },
        "tags": [],
        "id": "709e431b"
      },
      "source": [
        "# Matches and pairs operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b20d3d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.528718Z",
          "iopub.status.busy": "2023-06-22T11:51:29.528372Z",
          "iopub.status.idle": "2023-06-22T11:51:29.549099Z",
          "shell.execute_reply": "2023-06-22T11:51:29.548062Z"
        },
        "papermill": {
          "duration": 0.038726,
          "end_time": "2023-06-22T11:51:29.551463",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.512737",
          "status": "completed"
        },
        "tags": [],
        "id": "d1b20d3d"
      },
      "outputs": [],
      "source": [
        "def merge_kpts_matches(kpts, matches, new_kpts, new_matches, cap = None):\n",
        "    # merging kpts\n",
        "    prev_len = dict()\n",
        "    for new_key in new_kpts:\n",
        "        if new_key in kpts:\n",
        "            old_len = len(kpts[new_key])\n",
        "            kpts[new_key] = np.concatenate([kpts[new_key], new_kpts[new_key]], axis=0)\n",
        "        else:\n",
        "            old_len = 0\n",
        "            kpts[new_key] = new_kpts[new_key]\n",
        "        prev_len[new_key] = old_len\n",
        "    for new_key1 in new_matches:\n",
        "        for new_key2 in new_matches[new_key1]:\n",
        "            old_len1 = prev_len[new_key1]\n",
        "            old_len2 = prev_len[new_key2]\n",
        "            new_match = new_matches[new_key1][new_key2] + [old_len1, old_len2]\n",
        "            if cap is not None and len(new_match) > cap:\n",
        "                keep = np.random.choice(len(new_match), cap, replace=False)\n",
        "                new_match = new_match[keep, :]\n",
        "            if new_key1 in matches and new_key2 in matches[new_key1]:\n",
        "                matches[new_key1][new_key2] = np.concatenate(\n",
        "                    [\n",
        "                        matches[new_key1][new_key2],\n",
        "                        new_match,\n",
        "                    ],\n",
        "                    axis=0,\n",
        "                )\n",
        "            else:\n",
        "                if new_key1 not in matches:\n",
        "                    matches[new_key1] = dict()\n",
        "                matches[new_key1][new_key2] = new_match\n",
        "    return kpts, matches\n",
        "def keep_matches(matches, max_num=None):\n",
        "    if max_num is None:\n",
        "        return matches\n",
        "    if len(matches) > max_num:\n",
        "        # randomly selecting max_num matches\n",
        "        matches = np.random.choice(matches, max_num, replace=False)\n",
        "    return matches\n",
        "def keep_pairs(index_pairs, max_num_pairs=20):\n",
        "    new_count = 0\n",
        "    old_count = 0\n",
        "    new_idx_count = defaultdict(int)\n",
        "    new_pairs = defaultdict(list)\n",
        "    for key1 in index_pairs:\n",
        "        # sorting pairs by number of pairs\n",
        "        index_pairs[key1] = sorted(index_pairs[key1], key=lambda x: x[2], reverse=True)\n",
        "        for pair in index_pairs[key1]:\n",
        "            old_count += 1\n",
        "            idx1 = key1\n",
        "            idx2 = pair[0]\n",
        "            if new_idx_count[key1] < max_num_pairs:\n",
        "                new_pairs[idx1].append(pair)\n",
        "                new_count += 1\n",
        "                new_idx_count[idx1] += 1\n",
        "                new_idx_count[idx2] += 1\n",
        "            else:\n",
        "                continue\n",
        "    if DEBUG:\n",
        "        print(f\"origin pairs: {old_count}, kept pairs: {new_count}\")\n",
        "    return index_pairs\n",
        "def select_matches(matches, keep_ratio = 0.01):\n",
        "    max_matches = defaultdict(int)\n",
        "    old_matches_count = 0\n",
        "    for key1 in matches:\n",
        "        for key2 in matches[key1]:\n",
        "            max_matches[key1] = max(max_matches[key1], len(matches[key1][key2]))\n",
        "            max_matches[key2] = max(max_matches[key2], len(matches[key1][key2]))\n",
        "            old_matches_count +=1\n",
        "    new_matches_count = 0\n",
        "    new_matches = defaultdict(dict)\n",
        "    for key1 in matches:\n",
        "        for key2 in matches[key1]:\n",
        "            n_matches = len(matches[key1][key2])\n",
        "            if n_matches > max_matches[key1] * keep_ratio or n_matches > max_matches[key2] * keep_ratio:\n",
        "                new_matches[key1][key2] = matches[key1][key2]\n",
        "                new_matches_count+=1\n",
        "    if DEBUG:\n",
        "        print(f\"origin matches: {old_matches_count}, kept matches: {new_matches_count}\")\n",
        "    return new_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3bd385",
      "metadata": {
        "papermill": {
          "duration": 0.013837,
          "end_time": "2023-06-22T11:51:29.579822",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.565985",
          "status": "completed"
        },
        "tags": [],
        "id": "da3bd385"
      },
      "source": [
        "# Getting matrices from matches and keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9132a26",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.613118Z",
          "iopub.status.busy": "2023-06-22T11:51:29.612057Z",
          "iopub.status.idle": "2023-06-22T11:51:29.621304Z",
          "shell.execute_reply": "2023-06-22T11:51:29.620277Z"
        },
        "papermill": {
          "duration": 0.029463,
          "end_time": "2023-06-22T11:51:29.623855",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.594392",
          "status": "completed"
        },
        "tags": [],
        "id": "c9132a26"
      },
      "outputs": [],
      "source": [
        "def get_fms(kpts, matches):\n",
        "    prev_len = dict()\n",
        "    fms = defaultdict(dict)\n",
        "    print(\"Get Fundamental Matrix\")\n",
        "    for key1 in tqdm(matches):\n",
        "        for key2 in matches[key1]:\n",
        "            match = matches[key1][key2]\n",
        "            mkpts1 = kpts[key1][match[:, 0]]\n",
        "            mkpts2 = kpts[key2][match[:, 1]]\n",
        "            Fm, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, FM_PARAMS[\"ransacReprojThreshold\"], FM_PARAMS[\"confidence\"], FM_PARAMS[\"maxIters\"])\n",
        "            # keeping inliers matches\n",
        "            # printing how many matches are inliers\n",
        "            # print(f\"key1: {key1}, key2: {key2}, inliers: {len(new_match)}/{len(match)}\")\n",
        "            if FM_PARAMS[\"removeOutliers\"] == True:\n",
        "                new_match = match[inliers.ravel() == 1]\n",
        "                matches[key1][key2] = new_match\n",
        "            fms[key1][key2] = Fm\n",
        "    # print(Fm.shape)\n",
        "    return kpts, matches, fms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7cd9f09",
      "metadata": {
        "papermill": {
          "duration": 0.013845,
          "end_time": "2023-06-22T11:51:29.651581",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.637736",
          "status": "completed"
        },
        "tags": [],
        "id": "e7cd9f09"
      },
      "source": [
        "# Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86045301",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:29.681785Z",
          "iopub.status.busy": "2023-06-22T11:51:29.681067Z",
          "iopub.status.idle": "2023-06-22T11:51:40.661454Z",
          "shell.execute_reply": "2023-06-22T11:51:40.660352Z"
        },
        "papermill": {
          "duration": 10.998212,
          "end_time": "2023-06-22T11:51:40.664215",
          "exception": false,
          "start_time": "2023-06-22T11:51:29.666003",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86045301",
        "outputId": "19ec08d1-f791-4566-9779-255606d14bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-38c9089f9096>:38: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
            "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init AffNetHardNetDetector\n",
            "Longer edge will be resized to 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-38c9089f9096>:50: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
            "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init AffNetHardNetDetector\n",
            "Longer edge will be resized to 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-38c9089f9096>:66: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
            "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init AffNetHardNetDetector\n",
            "Longer edge will be resized to 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-38c9089f9096>:58: DeprecationWarning: `LAFAffNetShapeEstimator` default behaviour is changed and now it does preserve original LAF orientation. Make sure your code accounts for this.\n",
            "  aff_module=KF.LAFAffNetShapeEstimator(False).eval(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init AffNetHardNetDetector\n",
            "Longer edge will be resized to 1600\n"
          ]
        }
      ],
      "source": [
        "if MODEL_DICT[\"Keynet\"][\"enable\"]:\n",
        "    keynet_model = (\n",
        "        AffNetHardNet(num_features=8000, upright=False, device=device, detector=\"keynet\")\n",
        "        .to(device)\n",
        "        .eval()\n",
        "    )\n",
        "    keynet_detector = AffNetHardNetDetector(keynet_model, resize_long_edge_to=MODEL_DICT[\"Keynet\"][\"resize_long_edge_to\"])\n",
        "    laf_matcher = LafMatcher(device=device)\n",
        "if MODEL_DICT[\"GFTT\"][\"enable\"]:\n",
        "    gftt_model = (\n",
        "        AffNetHardNet(num_features=8000, upright=False, device=device, detector=\"GFTT\")\n",
        "        .to(device)\n",
        "        .eval()\n",
        "    )\n",
        "    gftt_detector = AffNetHardNetDetector(gftt_model, resize_long_edge_to=MODEL_DICT[\"GFTT\"][\"resize_long_edge_to\"])\n",
        "    laf_matcher = LafMatcher(device=device)\n",
        "if MODEL_DICT[\"DoG\"][\"enable\"]:\n",
        "    DoG_model = (\n",
        "        AffNetHardNet(num_features=8000, upright=False, device=device, detector=\"DoG\")\n",
        "        .to(device)\n",
        "        .eval()\n",
        "    )\n",
        "    DoG_detector = AffNetHardNetDetector(DoG_model, resize_long_edge_to=MODEL_DICT[\"DoG\"][\"resize_long_edge_to\"])\n",
        "    laf_matcher = LafMatcher(device=device)\n",
        "if MODEL_DICT[\"Harris\"][\"enable\"]:\n",
        "    harris_model = (\n",
        "        AffNetHardNet(num_features=8000, upright=False, device=device, detector=\"Harris\")\n",
        "        .to(device)\n",
        "        .eval()\n",
        "    )\n",
        "    harris_detector = AffNetHardNetDetector(harris_model, resize_long_edge_to=MODEL_DICT[\"Harris\"][\"resize_long_edge_to\"])\n",
        "    laf_matcher = LafMatcher(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25fc181",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:40.698804Z",
          "iopub.status.busy": "2023-06-22T11:51:40.698439Z",
          "iopub.status.idle": "2023-06-22T11:51:40.707407Z",
          "shell.execute_reply": "2023-06-22T11:51:40.706337Z"
        },
        "papermill": {
          "duration": 0.028113,
          "end_time": "2023-06-22T11:51:40.710101",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.681988",
          "status": "completed"
        },
        "tags": [],
        "id": "d25fc181"
      },
      "outputs": [],
      "source": [
        "# Util to check if the pairs are identital\n",
        "def compare_pairs(pairs1, pairs2):\n",
        "    pair1_dict = dict()\n",
        "    pair2_dict = dict()\n",
        "    for idx1 in tqdm(range(len(pairs1) - 1)):\n",
        "        for pair in pairs1[idx1]:\n",
        "            pair1_dict[(idx1, pair[0])] = 0\n",
        "    for idx2 in tqdm(range(len(pairs2) - 1)):\n",
        "        for pair in pairs2[idx2]:\n",
        "            pair2_dict[(idx2, pair[0])] = 0\n",
        "    for key in tqdm(pair1_dict):\n",
        "        if key not in pair2_dict:\n",
        "            print(f\"Key{key} not in pair2_dict\")\n",
        "    for key in tqdm(pair2_dict):\n",
        "        if key not in pair1_dict:\n",
        "            print(f\"Key{key} not in pair1_dict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404dc005",
      "metadata": {
        "papermill": {
          "duration": 0.014183,
          "end_time": "2023-06-22T11:51:40.739204",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.725021",
          "status": "completed"
        },
        "tags": [],
        "id": "404dc005"
      },
      "source": [
        "# Function to generate scene db for reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82b5b79",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:40.770444Z",
          "iopub.status.busy": "2023-06-22T11:51:40.769435Z",
          "iopub.status.idle": "2023-06-22T11:51:40.789099Z",
          "shell.execute_reply": "2023-06-22T11:51:40.788072Z"
        },
        "papermill": {
          "duration": 0.038176,
          "end_time": "2023-06-22T11:51:40.791664",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.753488",
          "status": "completed"
        },
        "tags": [],
        "id": "c82b5b79"
      },
      "outputs": [],
      "source": [
        "def generate_scene_db(dataset, scene):\n",
        "    feature_det_start = time()\n",
        "    # Processing a scene and writing matches and keypoints to the database\n",
        "    img_dir = f\"{SRC}/{MODE}/{dataset}/{scene}/images\"\n",
        "    if not os.path.exists(img_dir):\n",
        "        print(\"Image dir does not exist:\", img_dir)\n",
        "        return\n",
        "    img_fnames = [f\"{SRC}/{MODE}/{x}\" for x in data_dict[dataset][scene]]\n",
        "    print(f\"Got {len(img_fnames)} images\")\n",
        "    matches = dict()\n",
        "    kpts = dict()\n",
        "    if MODEL_DICT[\"Keynet\"][\"enable\"]:\n",
        "        f_lafs, f_kpts, f_descs, f_raw_size = keynet_detector.detect_features(\n",
        "            img_fnames\n",
        "        )\n",
        "        keynet_pairs, keynet_kpts, keynet_matches, keynet_rois = laf_matcher.match(\n",
        "            img_fnames, f_lafs, f_kpts, f_descs, f_raw_size\n",
        "        )\n",
        "        if not MODEL_DICT[\"Keynet\"][\"pair_only\"]:\n",
        "            kpts, matches = merge_kpts_matches(kpts, matches, keynet_kpts, keynet_matches, MATCHES_CAP)\n",
        "    if MODEL_DICT[\"GFTT\"][\"enable\"]:\n",
        "        gftt_lafs, gftt_kpts, gftt_descs, gftt_raw_size = gftt_detector.detect_features(\n",
        "            img_fnames\n",
        "        )\n",
        "        index_pairs, gftt_kpts, gftt_matches, gftt_rois = laf_matcher.match(\n",
        "            img_fnames, gftt_lafs, gftt_kpts, gftt_descs, gftt_raw_size\n",
        "        )\n",
        "        kpts, matches = merge_kpts_matches(kpts, matches, gftt_kpts, gftt_matches, MATCHES_CAP)\n",
        "    if MODEL_DICT[\"DoG\"][\"enable\"]:\n",
        "        DoG_lafs, DoG_kpts, DoG_descs, DoG_raw_size = DoG_detector.detect_features(\n",
        "            img_fnames\n",
        "        )\n",
        "        index_pairs, DoG_kpts, DoG_matches, DoG_rois = laf_matcher.match(\n",
        "            img_fnames, DoG_lafs, DoG_kpts, DoG_descs, DoG_raw_size\n",
        "        )\n",
        "        kpts, matches = merge_kpts_matches(kpts, matches, DoG_kpts, DoG_matches, MATCHES_CAP)\n",
        "    if MODEL_DICT[\"Harris\"][\"enable\"]:\n",
        "        harris_lafs, harris_kpts, harris_descs, harris_raw_size = harris_detector.detect_features(\n",
        "            img_fnames\n",
        "        )\n",
        "        harris_pairs, harris_kpts, harris_matches, harris_rois = laf_matcher.match(\n",
        "            img_fnames, harris_lafs, harris_kpts, harris_descs, harris_raw_size\n",
        "        )\n",
        "        kpts, matches = merge_kpts_matches(kpts, matches, harris_kpts, harris_matches, MATCHES_CAP)\n",
        "        # compare_pairs(keynet_pairs, harris_pairs)\n",
        "    # Getting matrices\n",
        "    kpts, matches, fms = get_fms(kpts, matches)\n",
        "    matches = select_matches(matches, MATCH_FILTER_RATIO)\n",
        "    if DEBUG:\n",
        "        import random\n",
        "        random.seed(0)\n",
        "        for i in range(5):\n",
        "            print(matches.keys())\n",
        "            key1 = random.choice(list(matches.keys()))\n",
        "            key2 = random.choice(list(matches[key1].keys()))\n",
        "            print(key1, key2)\n",
        "            fname1, fname2 = os.path.join(img_dir, key1), os.path.join(img_dir, key2)\n",
        "            print(\"Plot Combined matches\")\n",
        "            plot_images_with_keypoints(\n",
        "                fname1, fname2, kpts[key1], kpts[key2], matches[key1][key2]\n",
        "            )\n",
        "    # Writing to database\n",
        "    feature_dir = f\"featureout/{dataset}_{scene}\"\n",
        "    if not os.path.isdir(feature_dir):\n",
        "        os.makedirs(feature_dir, exist_ok=True)\n",
        "    database_path = f\"{feature_dir}/colmap.db\"\n",
        "    if os.path.isfile(database_path):\n",
        "        os.remove(database_path)\n",
        "    db = COLMAPDatabase.connect(database_path)\n",
        "    db.create_tables() # was said.\n",
        "    single_camera = False\n",
        "    print(\"Add kpts and matches to database\")\n",
        "    add_kpts_matches(db, img_dir, kpts, matches, fms)\n",
        "    feature_det_end = time()\n",
        "    matching_time = feature_det_end - feature_det_start\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return matching_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4821204f",
      "metadata": {
        "papermill": {
          "duration": 0.013847,
          "end_time": "2023-06-22T11:51:40.820367",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.806520",
          "status": "completed"
        },
        "tags": [],
        "id": "4821204f"
      },
      "source": [
        "# Function of reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d460bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:40.850333Z",
          "iopub.status.busy": "2023-06-22T11:51:40.849947Z",
          "iopub.status.idle": "2023-06-22T11:51:40.863427Z",
          "shell.execute_reply": "2023-06-22T11:51:40.862276Z"
        },
        "papermill": {
          "duration": 0.031221,
          "end_time": "2023-06-22T11:51:40.865818",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.834597",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "15d460bf"
      },
      "outputs": [],
      "source": [
        "def reconstruct_from_db(dataset, scene):\n",
        "    scene_result = {}\n",
        "    reconst_start = time()\n",
        "    img_dir = f\"{SRC}/{MODE}/{dataset}/{scene}/images\"\n",
        "    if not os.path.exists(img_dir):\n",
        "        print(\"Image dir does not exist:\", img_dir)\n",
        "        return\n",
        "    feature_dir = f\"featureout/{dataset}_{scene}\"\n",
        "    database_path = f\"{feature_dir}/colmap.db\"\n",
        "    db = COLMAPDatabase.connect(database_path)\n",
        "    output_path = f\"{feature_dir}/colmap_rec\"\n",
        "    t = time()\n",
        "    gc.collect()\n",
        "     # Skipping match_exhaustive\n",
        "     # pycolmap.match_exhaustive(database_path, match_options)\n",
        "    t = time() - t\n",
        "    print(f\"RANSAC in  {t:.4f} sec\")\n",
        "    t = time()\n",
        "    # By default colmap does not generate a reconstruction if less than 10 images are registered. Lowering it to 3:\n",
        "    mapper_options = pycolmap.IncrementalMapperOptions()\n",
        "    mapper_options.min_model_size = 3\n",
        "    for attribute_name in dir(mapper_options):\n",
        "        if not attribute_name.startswith(\"__\"):\n",
        "            attribute_value = getattr(mapper_options, attribute_name)\n",
        "            print(f\"{attribute_name}: {attribute_value}\")\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    maps = pycolmap.incremental_mapping(\n",
        "        database_path=database_path,\n",
        "        image_path=img_dir,\n",
        "        output_path=output_path,\n",
        "        options=mapper_options,\n",
        "    )\n",
        "    print(maps)\n",
        "    # clear_output(wait=False)\n",
        "    t = time() - t\n",
        "    print(f\"Reconstruction done in  {t:.4f} sec\")\n",
        "    imgs_registered = 0\n",
        "    best_idx = None\n",
        "    print(\"It was said: (Looking for the best reconstruction)\")\n",
        "    if isinstance(maps, dict):\n",
        "        for idx1, rec in maps.items():\n",
        "            print(idx1, rec.summary())\n",
        "            if len(rec.images) > imgs_registered:\n",
        "                imgs_registered = len(rec.images)\n",
        "                best_idx = idx1\n",
        "    if best_idx is not None:\n",
        "        print(maps[best_idx].summary())\n",
        "        for k, im in maps[best_idx].images.items():\n",
        "            key1 = f\"{dataset}/{scene}/images/{im.name}\"\n",
        "            scene_result[key1] = {}\n",
        "            scene_result[key1][\"R\"] = deepcopy(im.rotmat())\n",
        "            scene_result[key1][\"t\"] = deepcopy(np.array(im.tvec))\n",
        "    gc.collect()\n",
        "    reconst_end = time()\n",
        "    reconst_time = reconst_end - reconst_start\n",
        "    return scene_result, reconst_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce3ed1d",
      "metadata": {
        "papermill": {
          "duration": 0.014498,
          "end_time": "2023-06-22T11:51:40.894726",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.880228",
          "status": "completed"
        },
        "tags": [],
        "id": "1ce3ed1d"
      },
      "source": [
        "# Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033d2822",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:40.925071Z",
          "iopub.status.busy": "2023-06-22T11:51:40.924704Z",
          "iopub.status.idle": "2023-06-22T11:51:41.068574Z",
          "shell.execute_reply": "2023-06-22T11:51:41.067046Z"
        },
        "papermill": {
          "duration": 0.162365,
          "end_time": "2023-06-22T11:51:41.071394",
          "exception": false,
          "start_time": "2023-06-22T11:51:40.909029",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "033d2822",
        "outputId": "05005363-e821-486d-d116-d7ffebf89d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2cfa01ab573141e4 2fa124afd1f74f38\n",
            "Image dir does not exist: /content/drive/MyDrive/3DF2DD/3DF2D/test/2cfa01ab573141e4/2fa124afd1f74f38/images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image dir does not exist: /content/drive/MyDrive/3DF2DD/3DF2D/test/2cfa01ab573141e4/2fa124afd1f74f38/images\n"
          ]
        }
      ],
      "source": [
        "# Main loop to add kpts and matches\n",
        "datasets = []\n",
        "time_dict = dict()\n",
        "for dataset in data_dict:\n",
        "    datasets.append(dataset)\n",
        "if DEBUG:\n",
        "    matching_start = time()\n",
        "    for dataset, scene in all_scenes:\n",
        "        print(dataset, scene)\n",
        "        time_dict[\"matching-\" + scene] = generate_scene_db(dataset, scene)\n",
        "    matching_end = time()\n",
        "    time_dict[\"matching-TOTAL\"] = matching_end - matching_start\n",
        "else:\n",
        "    # Running db generation and reconstuction with multiprocessing if not DEBUG\n",
        "    out_results = defaultdict(dict)\n",
        "    total_start = time()\n",
        "    with concurrent.futures.ProcessPoolExecutor(max_workers=NUM_CORES) as executors:\n",
        "        futures = defaultdict(dict)\n",
        "        for dataset, scene in all_scenes:\n",
        "            print(dataset, scene)\n",
        "            time_dict[\"matching-\" + scene] = generate_scene_db(dataset, scene)\n",
        "            futures[dataset][scene] = executors.submit(reconstruct_from_db, dataset, scene)\n",
        "        for dataset, scene in all_scenes:\n",
        "            result = futures[dataset][scene].result()\n",
        "            if result is not None:\n",
        "                out_results[dataset][scene], time_dict[\"reconst-\" + scene] = result\n",
        "    total_end = time()\n",
        "    time_dict[\"TOTAL\"] = total_end - total_start"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9ccc2f",
      "metadata": {
        "papermill": {
          "duration": 0.014276,
          "end_time": "2023-06-22T11:51:41.100873",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.086597",
          "status": "completed"
        },
        "tags": [],
        "id": "6f9ccc2f"
      },
      "source": [
        "# Reconstruction Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46045aee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:41.132342Z",
          "iopub.status.busy": "2023-06-22T11:51:41.131247Z",
          "iopub.status.idle": "2023-06-22T11:51:41.139940Z",
          "shell.execute_reply": "2023-06-22T11:51:41.138851Z"
        },
        "papermill": {
          "duration": 0.026261,
          "end_time": "2023-06-22T11:51:41.142102",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.115841",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "46045aee"
      },
      "outputs": [],
      "source": [
        "# Main loop for reconstruction\n",
        "if DEBUG:\n",
        "    reconst_start = time()\n",
        "    out_results = defaultdict(dict)\n",
        "    with concurrent.futures.ProcessPoolExecutor(max_workers=NUM_CORES) as executors:\n",
        "        futures = defaultdict(dict)\n",
        "        for dataset, scene in all_scenes:\n",
        "            futures[dataset][scene] = executors.submit(reconstruct_from_db, dataset, scene)\n",
        "            print(\"Submitted\", dataset, scene)\n",
        "        for dataset, scene in all_scenes:\n",
        "            result = futures[dataset][scene].result()\n",
        "            if result is not None:\n",
        "                out_results[dataset][scene], time_dict[\"reconst-\" + scene] = result\n",
        "    reconst_end = time()\n",
        "    time_dict[\"reconst-TOTAL\"] = reconst_end - reconst_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c5723b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:41.172309Z",
          "iopub.status.busy": "2023-06-22T11:51:41.171968Z",
          "iopub.status.idle": "2023-06-22T11:51:41.177716Z",
          "shell.execute_reply": "2023-06-22T11:51:41.176727Z"
        },
        "papermill": {
          "duration": 0.023101,
          "end_time": "2023-06-22T11:51:41.179911",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.156810",
          "status": "completed"
        },
        "tags": [],
        "id": "41c5723b"
      },
      "outputs": [],
      "source": [
        "make_project(out_results, data_dict, MODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1dd8009",
      "metadata": {
        "papermill": {
          "duration": 0.014122,
          "end_time": "2023-06-22T11:51:41.208146",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.194024",
          "status": "completed"
        },
        "tags": [],
        "id": "a1dd8009"
      },
      "source": [
        "# Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79551e28",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:41.238661Z",
          "iopub.status.busy": "2023-06-22T11:51:41.238255Z",
          "iopub.status.idle": "2023-06-22T11:51:41.282474Z",
          "shell.execute_reply": "2023-06-22T11:51:41.281414Z"
        },
        "papermill": {
          "duration": 0.062732,
          "end_time": "2023-06-22T11:51:41.285304",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.222572",
          "status": "completed"
        },
        "tags": [],
        "id": "79551e28"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from time import time\n",
        "def arr_to_str(a):\n",
        "    return \";\".join([str(x) for x in a.reshape(-1)])\n",
        "# Evaluation metric.\n",
        "@dataclass\n",
        "class Camera:\n",
        "    rotmat: np.array\n",
        "    tvec: np.array\n",
        "def quaternion_from_matrix(matrix):\n",
        "    M = np.array(matrix, dtype=np.float64, copy=False)[:4, :4]\n",
        "    m00 = M[0, 0]\n",
        "    m01 = M[0, 1]\n",
        "    m02 = M[0, 2]\n",
        "    m10 = M[1, 0]\n",
        "    m11 = M[1, 1]\n",
        "    m12 = M[1, 2]\n",
        "    m20 = M[2, 0]\n",
        "    m21 = M[2, 1]\n",
        "    m22 = M[2, 2]\n",
        "    # Symmetric matrix K.\n",
        "    K = np.array(\n",
        "        [\n",
        "            [m00 - m11 - m22, 0.0, 0.0, 0.0],\n",
        "            [m01 + m10, m11 - m00 - m22, 0.0, 0.0],\n",
        "            [m02 + m20, m12 + m21, m22 - m00 - m11, 0.0],\n",
        "            [m21 - m12, m02 - m20, m10 - m01, m00 + m11 + m22],\n",
        "        ]\n",
        "    )\n",
        "    K /= 3.0\n",
        "    # Quaternion is eigenvector of K that corresponds to largest eigenvalue.\n",
        "    w, V = np.linalg.eigh(K)\n",
        "    q = V[[3, 0, 1, 2], np.argmax(w)]\n",
        "    if q[0] < 0.0:\n",
        "        np.negative(q, q)\n",
        "    return q\n",
        "def evaluate_R_t(R_gt, t_gt, R, t, eps=1e-15):\n",
        "    t = t.flatten()\n",
        "    t_gt = t_gt.flatten()\n",
        "    q_gt = quaternion_from_matrix(R_gt)\n",
        "    q = quaternion_from_matrix(R)\n",
        "    q = q / (np.linalg.norm(q) + eps)\n",
        "    q_gt = q_gt / (np.linalg.norm(q_gt) + eps)\n",
        "    loss_q = np.maximum(eps, (1.0 - np.sum(q * q_gt) ** 2))\n",
        "    err_q = np.arccos(1 - 2 * loss_q)\n",
        "    GT_SCALE = np.linalg.norm(t_gt)\n",
        "    t = GT_SCALE * (t / (np.linalg.norm(t) + eps))\n",
        "    err_t = min(np.linalg.norm(t_gt - t), np.linalg.norm(t_gt + t))\n",
        "    return np.degrees(err_q), err_t\n",
        "def compute_dR_dT(R1, T1, R2, T2):\n",
        "    \"\"\"Given absolute (R, T) pairs for two cameras, compute the relative pose difference, from the first.\"\"\"\n",
        "    dR = np.dot(R2, R1.T)\n",
        "    dT = T2 - np.dot(dR, T1)\n",
        "    return dR, dT\n",
        "def compute_mAA(err_q, err_t, ths_q, ths_t):\n",
        "    \"\"\"Compute the mean average accuracy over a set of thresholds. Additionally returns the metric only over rotation and translation.\"\"\"\n",
        "    acc, acc_q, acc_t = [], [], []\n",
        "    for th_q, th_t in zip(ths_q, ths_t):\n",
        "        cur_acc_q = err_q <= th_q\n",
        "        cur_acc_t = err_t <= th_t\n",
        "        cur_acc = cur_acc_q & cur_acc_t\n",
        "        acc.append(cur_acc.astype(np.float32).mean())\n",
        "        acc_q.append(cur_acc_q.astype(np.float32).mean())\n",
        "        acc_t.append(cur_acc_t.astype(np.float32).mean())\n",
        "    return np.array(acc), np.array(acc_q), np.array(acc_t)\n",
        "def dict_from_csv(csv_path, has_header):\n",
        "    csv_dict = {}\n",
        "    with open(csv_path, \"r\") as f:\n",
        "        for i, l in enumerate(f):\n",
        "            if has_header and i == 0:\n",
        "                continue\n",
        "            if l:\n",
        "                image, dataset, scene, R_str, T_str = l.strip().split(\",\")\n",
        "                R = np.fromstring(R_str.strip(), sep=\";\").reshape(3, 3)\n",
        "                T = np.fromstring(T_str.strip(), sep=\";\")\n",
        "                if dataset not in csv_dict:\n",
        "                    csv_dict[dataset] = {}\n",
        "                if scene not in csv_dict[dataset]:\n",
        "                    csv_dict[dataset][scene] = {}\n",
        "                csv_dict[dataset][scene][image] = Camera(rotmat=R, tvec=T)\n",
        "    return csv_dict\n",
        "def eval_project(\n",
        "    project_csv_path,\n",
        "    ground_truth_csv_path,\n",
        "    rotation_thresholds_degrees_dict,\n",
        "    translation_thresholds_meters_dict,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Compute final metric given project and actual files. Thresholds are specified per dataset.\"\"\"\n",
        "    project_dict = dict_from_csv(project_csv_path, has_header=True)\n",
        "    gt_dict = dict_from_csv(ground_truth_csv_path, has_header=True)\n",
        "    # Checking that all required keys exist in the project file\n",
        "    for dataset in gt_dict:\n",
        "        assert dataset in project_dict, f\"Unknown dataset: {dataset}\"\n",
        "        for scene in gt_dict[dataset]:\n",
        "            assert (\n",
        "                scene in project_dict[dataset]\n",
        "            ), f\"Unknown scene: {dataset}->{scene}\"\n",
        "            for image in gt_dict[dataset][scene]:\n",
        "                assert (\n",
        "                    image in project_dict[dataset][scene]\n",
        "                ), f\"Unknown image: {dataset}->{scene}->{image}\"\n",
        "    # Iterating over all scenes\n",
        "    if verbose:\n",
        "        t = time()\n",
        "        print(\"*** METRICS ***\")\n",
        "    metrics_per_dataset = []\n",
        "    for dataset in gt_dict:\n",
        "        metrics_per_scene = []\n",
        "        for scene in gt_dict[dataset]:\n",
        "            err_q_all = []\n",
        "            err_t_all = []\n",
        "            images = [camera for camera in gt_dict[dataset][scene]]\n",
        "            # Processing all pairs in a scene\n",
        "            for i in range(len(images)):\n",
        "                for j in range(i + 1, len(images)):\n",
        "                    gt_i = gt_dict[dataset][scene][images[i]]\n",
        "                    gt_j = gt_dict[dataset][scene][images[j]]\n",
        "                    dR_gt, dT_gt = compute_dR_dT(\n",
        "                        gt_i.rotmat, gt_i.tvec, gt_j.rotmat, gt_j.tvec\n",
        "                    )\n",
        "                    pred_i = project_dict[dataset][scene][images[i]]\n",
        "                    pred_j = project_dict[dataset][scene][images[j]]\n",
        "                    dR_pred, dT_pred = compute_dR_dT(\n",
        "                        pred_i.rotmat, pred_i.tvec, pred_j.rotmat, pred_j.tvec\n",
        "                    )\n",
        "                    err_q, err_t = evaluate_R_t(dR_gt, dT_gt, dR_pred, dT_pred)\n",
        "                    err_q_all.append(err_q)\n",
        "                    err_t_all.append(err_t)\n",
        "            mAA, mAA_q, mAA_t = compute_mAA(\n",
        "                err_q=err_q_all,\n",
        "                err_t=err_t_all,\n",
        "                ths_q=rotation_thresholds_degrees_dict[(dataset, scene)],\n",
        "                ths_t=translation_thresholds_meters_dict[(dataset, scene)],\n",
        "            )\n",
        "            if verbose:\n",
        "                print(\n",
        "                    f\"{dataset} / {scene} ({len(images)} images, {len(err_q_all)} pairs) -> mAA={np.mean(mAA):.06f}, mAA_q={np.mean(mAA_q):.06f}, mAA_t={np.mean(mAA_t):.06f}\"\n",
        "                )\n",
        "            metrics_per_scene.append(np.mean(mAA))\n",
        "        metrics_per_dataset.append(np.mean(metrics_per_scene))\n",
        "        if verbose:\n",
        "            print(f\"{dataset} -> mAA={np.mean(metrics_per_scene):.06f}\")\n",
        "            print()\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"Final metric -> mAA={np.mean(metrics_per_dataset):.06f} (t: {time() - t} sec.)\"\n",
        "        )\n",
        "        print()\n",
        "    return np.mean(metrics_per_dataset)\n",
        "# Setting rotation thresholds per scene.\n",
        "rotation_thresholds_degrees_dict = {\n",
        "    **{\n",
        "        (\"haiper\", scene): np.linspace(1, 10, 10)\n",
        "        for scene in [\"bike\", \"chairs\", \"fountain\"]\n",
        "    },\n",
        "    **{(\"heritage\", scene): np.linspace(1, 10, 10) for scene in [\"cyprus\", \"dioscuri\"]},\n",
        "    **{(\"heritage\", \"wall\"): np.linspace(0.2, 10, 10)},\n",
        "    **{(\"urban\", \"kyiv-puppet-theater\"): np.linspace(1, 10, 10)},\n",
        "}\n",
        "translation_thresholds_meters_dict = {\n",
        "    **{\n",
        "        (\"haiper\", scene): np.geomspace(0.05, 0.5, 10)\n",
        "        for scene in [\"bike\", \"chairs\", \"fountain\"]\n",
        "    },\n",
        "    **{\n",
        "        (\"heritage\", scene): np.geomspace(0.1, 2, 10)\n",
        "        for scene in [\"cyprus\", \"dioscuri\"]\n",
        "    },\n",
        "    **{(\"heritage\", \"wall\"): np.geomspace(0.05, 1, 10)},\n",
        "    **{(\"urban\", \"kyiv-puppet-theater\"): np.geomspace(0.5, 5, 10)},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48003eab",
      "metadata": {
        "papermill": {
          "duration": 0.014124,
          "end_time": "2023-06-22T11:51:41.315018",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.300894",
          "status": "completed"
        },
        "tags": [],
        "id": "48003eab"
      },
      "source": [
        "# Run evaluation and log outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010b9a44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:41.345741Z",
          "iopub.status.busy": "2023-06-22T11:51:41.345388Z",
          "iopub.status.idle": "2023-06-22T11:51:41.358356Z",
          "shell.execute_reply": "2023-06-22T11:51:41.357352Z"
        },
        "papermill": {
          "duration": 0.030979,
          "end_time": "2023-06-22T11:51:41.360788",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.329809",
          "status": "completed"
        },
        "tags": [],
        "id": "010b9a44"
      },
      "outputs": [],
      "source": [
        "%%capture cap --no-stderr\n",
        "import datetime\n",
        "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "print(\"=========================================\")\n",
        "print(current_time)\n",
        "print(FM_PARAMS)\n",
        "print(LOG_DICT)\n",
        "print(MODEL_DICT)\n",
        "print(\"Match filter ratio = \", MATCH_FILTER_RATIO)\n",
        "for dataset in out_results:\n",
        "    for scene in out_results[dataset]:\n",
        "        print(\n",
        "            f\"Registered: {dataset} / {scene} -> {len(out_results[dataset][scene])}/{len(data_dict[dataset][scene])} images\"\n",
        "        )\n",
        "print(time_dict)\n",
        "if MODE == \"train\":\n",
        "    with open(f\"{SRC}/train/train_labels.csv\", \"r\") as fr, open(\n",
        "        \"ground_truth.csv\", \"w\"\n",
        "    ) as fw:\n",
        "        for i, l in enumerate(fr):\n",
        "            if i == 0:\n",
        "                fw.write(\n",
        "                    \"image_path,dataset,scene,rotation_matrix,translation_vector\\n\"\n",
        "                )\n",
        "            else:\n",
        "                dataset, scene, image, R, T = l.strip().split(\",\")\n",
        "                fw.write(f\"{image},{dataset},{scene},{R},{T}\\n\")\n",
        "    eval_project(\n",
        "        project_csv_path=\"project_train.csv\",\n",
        "        ground_truth_csv_path=\"ground_truth.csv\",\n",
        "        rotation_thresholds_degrees_dict=rotation_thresholds_degrees_dict,\n",
        "        translation_thresholds_meters_dict=translation_thresholds_meters_dict,\n",
        "        verbose=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f9ca48",
      "metadata": {
        "papermill": {
          "duration": 0.014646,
          "end_time": "2023-06-22T11:51:41.390922",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.376276",
          "status": "completed"
        },
        "tags": [],
        "id": "06f9ca48"
      },
      "source": [
        "Writing log to a text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6687cb0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T11:51:41.423375Z",
          "iopub.status.busy": "2023-06-22T11:51:41.422150Z",
          "iopub.status.idle": "2023-06-22T11:51:41.429642Z",
          "shell.execute_reply": "2023-06-22T11:51:41.428039Z"
        },
        "papermill": {
          "duration": 0.02592,
          "end_time": "2023-06-22T11:51:41.431961",
          "exception": false,
          "start_time": "2023-06-22T11:51:41.406041",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6687cb0c",
        "outputId": "935f03c8-62ed-42f4-ed0a-40e38d7eb29c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================\n",
            "2024-04-09_13-01-35\n",
            "{'ransacReprojThreshold': 5, 'confidence': 0.9999, 'maxIters': 50000, 'removeOutliers': True}\n",
            "{'mode': 'test', 'log_message': 'Final project', 'matches_cap': None, 'debug': False, 'debug_scene': ['chairs']}\n",
            "{'Keynet': {'enable': True, 'resize_long_edge_to': 1600, 'pair_only': False}, 'GFTT': {'enable': True, 'resize_long_edge_to': 1600}, 'DoG': {'enable': True, 'resize_long_edge_to': 1600}, 'Harris': {'enable': True, 'resize_long_edge_to': 1600}}\n",
            "Match filter ratio =  0.01\n",
            "{'matching-2fa124afd1f74f38': None, 'TOTAL': 0.2725179195404053}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(cap)\n",
        "if is_local:\n",
        "    with open(\"log.txt\", \"a\") as f:\n",
        "        f.write(str(cap))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 44.217135,
      "end_time": "2023-06-22T11:51:44.377634",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-06-22T11:51:00.160499",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}